# -*- coding: utf-8 -*-
"""Lab12Ex.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1koG9nqCAHibsV7QYqGm7mtGGapWfih0N
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import LSTM
from tensorflow.keras.layers import Dropout

series = pd.read_csv(r"/content/temperaturi_max.csv")
print(series.head(10))
print(series.size)

print(series.describe())

#get all the data until 1990
x_train = series.iloc[0:3285,:]
print("Train dataset\n", x_train.head())
print(x_train.size)
print(x_train.loc[3284,:])

x_test = series.iloc[3285:3650]
print("Test dataset\n", x_test.head())
print(x_test.size)
print(x_test.loc[3649,:])

y_train = x_train['Temperatura']
y_test = x_test['Temperatura']

x_train = x_train['Data']
x_test =  x_test['Data']


print("x_test\n", x_test.head())
print("x_test\n", x_test.shape)
print("y_test\n", y_test.head())
print("y_test\n", y_test.shape)

import numpy as np
import matplotlib.pyplot as plt
from pandas import read_csv
import math
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import LSTM
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error
import pandas

dataset = pd.read_csv(r"/content/temperaturi_max.csv", engine ='python')
print(series.head(10))
print(series.size)

dataset = pd.read_csv(r"/content/temperaturi_max.csv",usecols=[1], engine ='python')
print(series.head(10))
print(len(dataset[1:]))
plt.plot(dataset, color='red')
plt.show()

def create_dataset(dataset, look_back=1):
  dataX, dataY = [], []
  for i in range(len(dataset)-look_back-1):
    a = dataset[i:(i+look_back), 0]
    dataX.append(a)
    dataY.append(dataset[i+look_back, 0])
  return np.array(dataX), np.array(dataY)

np.random.seed(7)

dataframe = pd.read_csv(r"/content/temperaturi_max.csv",usecols=[1], engine ='python')
dataset = dataframe.values
dataset = dataset.astype('float32')

scaler = MinMaxScaler(feature_range=(0,1))
dataset = scaler.fit_transform(dataset)

#selectam datele pana in 1990 pt train si cele din 1990 pt test
train, test = dataset[0:3285,:], dataset[3285:3650]
print("\n\n\nTRAIN\n", train)
print("\n\n\nTEST\n", test)


look_back=1
trainX, trainY = create_dataset(train, look_back)
testX, testY = create_dataset(test,look_back)

trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))
testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))

#Create model + train
model = Sequential()
model.add(LSTM(4, input_shape=(1, look_back)))
model.add(Dense(1))
model.compile(loss='mean_squared_error', optimizer='adam')
model.fit(trainX, trainY, epochs=100, batch_size=1, verbose=2)

trainPredict=model.predict(trainX)
testPredict = model.predict(testX)

trainPredict = scaler.inverse_transform(trainPredict)
print(trainY)
#trainY = scaler.inverse_transform([trainY])

testPredict = scaler.inverse_transform(testPredict)
#testY = scaler.inverse_transform([testY])

#error

trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))
print('Scor antrenare: %.2f RMSE'% (trainScore))

testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))
print('Scor testare: %.2f RMSE'% (testScore))

trainPredictPlot = np.empty_like(dataset)
trainPredictPlot[:,:] = np.nan
trainPredictPlot[look_back:len(trainPredict)+look_back,:] = trainPredict

testPredictPlot = np.empty_like(dataset)
testPredictPlot[:,:] = np.nan
testPredictPlot[look_back:len(testPredict)+look_back,:] = testPredict

plt.plot(scaler.inverse_transform(dataset))
plt.plot(trainPredictPlot)
plt.plot(testPredictPlot)
plt.show()