# -*- coding: utf-8 -*-
"""L12Ex1_RNN with LSTM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10LkS6ZBQKxBZMYh-xRFuHBUJNdNQ0Gqz
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

training_data = pd.read_csv(r'FB.csv')
print("Capul de tabel in format csv\n", training_data.head())
print("Marime set de date - numar de linii\n", len(training_data))

training_data = training_data.iloc[:,1].values
print("Setul de date transformat in array\n", training_data)
print("Marime array - numar de elemente vector\n", len(training_data))

from google.colab import drive
drive.mount('/content/drive')

from sklearn.preprocessing import MinMaxScaler

#scaler = normalizare
scaler = MinMaxScaler()
training_data = scaler.fit_transform(training_data.reshape(-1, 1))

x_training_data = []
y_training_data = []

for i in range(40, len(training_data)):
  x_training_data.append(training_data[i-40:i, 0])
  y_training_data.append(training_data[i, 0])

print(len(x_training_data), len(y_training_data))
print(type(x_training_data))
print(x_training_data[0], "\n")
print(y_training_data[0], "\n")

#Transofmr listele in numpy arrays
x_training_data = np.array(x_training_data)
y_training_data = np.array(y_training_data)

#Verificam forma numpy arrays
print(x_training_data.shape)
print(y_training_data.shape)

#Facem teshaping Numpy array pentru a fi aliniat cu Tensor flow

x_training_data = np.reshape(x_training_data, (x_training_data.shape[0], 
                                               x_training_data.shape[1], 
                                               1))

print(x_training_data.shape)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import LSTM
from tensorflow.keras.layers import Dropout

#initializam RNN
rnn = Sequential()

#adaugam primul start LSTM
rnn.add(LSTM(units = 45, return_sequences = True, input_shape = (x_training_data.shape[1], 1 )))

#facem o regularizare dropout
rnn.add(Dropout(0.2))

#Adaugam inca 3 straturi LSTM cu regularizare
for i in [True, True, False]:
  rnn.add(LSTM(units = 45, return_sequences = i))
  rnn.add(Dropout(0.2))

#Adaugam stratul de iesire
rnn.add(Dense(units = 1))

#Compilam RNN
rnn.compile(optimizer = 'adam', loss = 'mean_squared_error')
#Antrenam RNN
rnn.fit(x_training_data, y_training_data, epochs = 100, batch_size = 32)

#importam setul de date de testare si le transformam in Numpy array
test_data = pd.read_csv("FB.csv")
test_data = test_data.iloc[:, 1].values

#Verificam forma setului
print(test_data.shape)
plt.plot(test_data)



#cream date de antrenare si testare nescalate( nenormalizate)
unscaled_training_data = pd.read_csv('FB.csv')
unscaled_test_data = pd.read_csv('FB_test_data (1).csv')

#Concatenam seturile pe coloana "Open"
all_data = pd.concat((unscaled_training_data['Open'], unscaled_test_data['Open']), axis = 0)
print(all_data.shape)
#Cream x_test_data cu fiecare zi din luna Ian +40 de zile inainte
x_test_data = all_data[len(all_data) - len(test_data) - 40:].values
x_test_data = np.reshape(x_test_data, (-1, 1))

print(x_test_data.shape)
#Scalare set de date
x_test_data = scaler.transform(x_test_data)
print(x_test_data[0])

#Groupam datele de testare 
final_x_test_data = []
for i in range(40, len(x_test_data)):
  final_x_test_data.append(x_test_data[i-40:i, 0])
print(final_x_test_data[0])
final_x_test_data = np.array(final_x_test_data)
print("Ca Numpy array\n", final_x_test_data[0])
#Reformare NumPy array pentru Tensor Flow
final_x_test_data = np.reshape(final_x_test_data, (final_x_test_data.shape[0],
                                                   final_x_test_data.shape[1],
                                                   1))

print(final_x_test_data.shape)
print(type(final_x_test_data))

#Generam valorile previzionate
predictions = rnn.predict(final_x_test_data)
#Afisam datele previzionate
plt.clf() #Stergem din canvas plotarea veche
plt.plot(prediction, color="green")

#Facem scalare valori previzionate si plotam
unscaled_predictions = scaler.inverse_transform(predictions)
plt.clf()
plt.plot(unscaled_predictions, color="red")
plt.title('Date previzionate nenormalizate')

plt.clf()
#Datele reale
plt.plot(test_data, color = 'blue')
plt.title('Date reale')

plt.clf()
plt.plot(test_data, color = 'blue')
plt.plot(unscaled_predictions, colors="red")
plt.title('Comparatie')

#Generam valorile previzionate
predictions = rnn.predict(final_x_test_data)
predictions = predictions + 0.03
#Afisam datele previzionate
plt.clf() #Stergem din canvas plotarea veche
plt.plot(predictions, color = "green")

plt.clf()
plt.plot(test_data, color = 'blue')
plt.plot(unscaled_predictions, colors="red")
plt.title('Comparatie')

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import LSTM
from tensorflow.keras.layers import Dropout

#initializam RNN
rnn = Sequential()

#adaugam primul start LSTM
rnn.add(LSTM(units = 45, return_sequences = True, input_shape = (x_training_data.shape[1], 1 )))

#facem o regularizare dropout
rnn.add(Dropout(0.2))

#Adaugam inca 3 straturi LSTM cu regularizare
for i in [True, True, False]:
  rnn.add(LSTM(units = 45, return_sequences = i))
  rnn.add(Dropout(0.2))

#Adaugam stratul de iesire
rnn.add(Dense(units = 1))

#Compilam RNN
rnn.compile(optimizer = 'adam', loss = 'mean_squared_error')
#Antrenam RNN
rnn.fit(x_training_data, y_training_data, epochs = 100, batch_size = 32)

#importam setul de date de testare si le transformam in Numpy array
test_data = pd.read_csv("FB.csv")
test_data = test_data.iloc[:, 1].values

#Verificam forma setului
print(test_data.shape)
plt.plot(test_data)