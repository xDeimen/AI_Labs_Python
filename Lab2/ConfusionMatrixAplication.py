import numpy as np

cm = np.array(
[[5825, 1,  49, 23, 7,  46, 30, 12, 21, 26],
 [1, 6651,  48, 25,10,  32, 19, 62, 111,    10],
 [2, 20, 5561, 69, 13, 10, 2, 45, 18, 2],
 [6, 26, 99, 5786, 5, 111, 1, 41, 110,79],
 [4, 10, 43, 6, 5533, 32, 11, 53, 34, 79],
 [3, 1, 2, 56, 0, 4954, 23, 0, 12, 5],
 [31, 4, 42, 22, 45, 103, 5806, 3, 34, 3],
 [0, 4, 30, 29, 5, 6, 0, 5817, 2, 28],
 [35, 6, 63, 58, 8, 59, 26, 13, 5394, 24],
 [16, 16, 21, 57, 216, 68, 0, 219, 115, 5693]])

def precision(label, confusion_matrix):
    col = confusion_matrix[:, label]
    return confusion_matrix[label, label]/col.sum()

def recall(label, confusion_matrix):
    row = confusion_matrix[label, :]
    return confusion_matrix[label, label] / row.sum()

def precision_macro_average(confusion_matrix):
    rows, columns = confusion_matrix.shape
    sum_of_precisions = 0
    for label in range(rows):
        sum_of_precisions += precision(label, confusion_matrix)
    return sum_of_precisions/rows

def recall_macro_average(confusion_matrix):
    rows, columns = confusion_matrix.shape
    sum_of_recalls = 0
    for label in range (columns):
        sum_of_recalls += recall(label, confusion_matrix)
    return sum_of_recalls/columns

print("label precision recall")
for label in range(10):
    print(f"{label:5d}{precision(label,cm):9.3f}{recall(label, cm):6.3f}")

print("precision total:", precision_macro_average(cm))
print("recall total:", recall_macro_average(cm))

def accuracy(confusion_matrix):
    diagonal_sum = confusion_matrix.trace()
    sum_of_all_elements = confusion_matrix.sum()
    return diagonal_sum / sum_of_all_elements

print("accuracy: ", accuracy(cm))